## Statically Combining Contexts with a Pure Function using Applicative

Functor is an incredible general and useful algebraic structure but it lacks an important ability: We cannot lift a binary or other n-ary functions into `n` functorial contexts or in other words we cannot combine several contexts with a function. When we try anyway we get stuck with functions in a context:

```javascript
const arrMap = f => xs =>
  xs.map((x, i) => f(x, i));
  
const add = x => y => x + y;

arrMap(add) ([1, 2, 3]); // [f, f, f]
```
`Functor` has no means to further apply these functions, because `map` expects a single pure function not a collection of partially applied ones.

### Extending functor to applicative

Let us extend the `Functor` type class by deducing a subclass with two additional properties. This new type class is called `Applicative` and encodes the algebraic structure of applicative functors.

#### `of` operation

```javascript
const of = x => /* function body */;
```
`of` puts whatever value is provided in the most minimal context. It is fully polymorphic in the value. Most minimal context is a rather fuzzy term, but during this chapter you will develop a better intuition.

#### `ap` operation and the applicative pattern

```javascript
const ap = tf => tx => /* function body */;
```
`ap` is a left-associative binary function that takes a partially applied pure function `tf` in a context `t` and a value `tx` in the same context, applies `f` to `x` within `t` and returns the result value again wrapped in `t`. Depending on the context there can be none, exactly one or many `x` values inside `t`.

Since `ap` expects a function within a context we must compose an `f` with `map` to get an `ft`. This composition forms the so called applicative pattern: `ap(map(f) (tx)) (ty)`.

We can compose several `ap` operations to combine `n` contexts with an `n`-ary function, as long as all contexts are of the same type: `ap(ap(map(f) (tx)) (ty)) (tz)`.

#### Monoidal in terms of contexts

`of` and `ap` only operate on contexts and are fully polymorphic on the values inside. `of` acts like an identity context and `ap` combines two context of the same type. The resemblance to monoids is obvious. `Applicative` combines functor and monoid in a meaningful way. It only inherits from the `Functor` type class but incorporates `Monoid` conceptually.

### Applicative at the type level

If Typescript would support higher-order type constructors the applicative operations would have the following types:

```javascript
// hypothetical type
type op = <F, A>(x: A) => F<A>;
type ap = <F, A, B>(tf: F<(x: A) => B>) => (tx: F<A>) => F<B>;
```
This is function application `<A, B>(f: (x: A) => B) => (x: A) => B`, but inside a functorial context `F`.

### The two notions of expressions

Looking at an expression like `[1, 2, 3]` it is just a collection of values of the same type. This is the notion of an expression as an ordinary value. Now an applicative functor has the characteristic to create meaning. As soon as we use our array in an applicative operation it is not an ordinary value anymore but a non-deterministic computation. An array is non-deterministic because it can contain none, one or many values. This is the notion of an expression as a computation. An applicative functor turns a value into a specific computation. You can think of it as a semantics machine. In a subsequent section of this chapter I will demonstrate an example for this distinction.

TODO: example

### Static combination of contexts

Every context affects its value(s) in a certain way. The non-deterministic context, for instance, either contains none, one or many values. The crucial property of applicative functors is that they perform the effect of its context exactly ONCE, without exception. If you combine two non-deterministic computations `xs`/`ys` with a binary pure function `f` by applying `ap(map(f) (xs)) (ys)`, the non-determinism of both values is combined. You cannot ignore the first or the last one or apply either of them twice. In other words the combination of applicative contexts is static or deterministic, because you can determine from the code in what manner the contexts will be combined:

```javascript
// Functor

const arrMap = f => xs =>
  xs.map((x, i) => f(x, i));

// Applicative

const arrAp = tf => tx =>
  arrFold(acc => f =>
    arrAppend(acc)
      (arrMap(x => f(x)) (tx)))
        ([])
          (tf);

// Foldable

const arrFold = f => init => xs => {
  let acc = init;
  
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (xs[i], i);

  return acc;
};

// Semigroup

const arrAppend = xs => ys =>
  (xs.push.apply(xs, ys), xs);

// function compostion

const comp = f => g => x => f(g(x));

// MAIN

const add = x => y => x + y;

const xs = [1, 2, 3],
  ys = [0, 20, 300];

comp(arrAp)
  (arrMap(add))
    (xs)
      (ys); // [1, 21, 301, 2, 22, 302, 3, 23, 303]
```
[run code](https://repl.it/repls/HotpinkShamelessLoopfusion)

We start with a composition of `map` and `ap`, which is the applicative pattern as already mentioned. Next we pass the array values or rather the non-deterministic computations to this composition. We still cannot determine the length of both arrays because they are non-deterministic but we can anticipate that the resulting array will be the cartesian product of both input arrays. The simple example above only uses array literals so we can actually determine the length of the resulting array, which is `3 * 3 = 9`. No matter what the pure function does with its values we will always stick with a result array of the same shape, namely with exactly nine elements.

The effect a context can have on its value(s) is not limited to quantity. Every context has its own effect, often rather subtle ones. This is exactly the part that renders applicative functors so general and hard to grasp. If you have understood a the context of an specific applicative instance you are far from having understood the concept in general. On the one hand it is hard to draw a universal conclusion from the perspective of a single applicative. On the other hand it is hard to conclude from an abstract description on the variety of contexts, which often have nothing in common.




The pure function `f` on the other hand is not context aware at all. The context in which it is being applied to values is opaque to `f`. The pure function is exposed to this context and cannot change any property that belongs to the latter. From the perspective of the context `f`'s application is completely mechanic and deterministic.

### Abstracting from nested application

`ap` expects two arguments and thus two contexts. If we want to combine more than two contexts we have to build a call tree of nested `ap` applications. However, since applicative computations are static, we can abstract from the nesting with a family of arity aware combinators:

```javascript
const liftA4 = ({map, ap}) => f => tw => tx => ty => tz =>
  ap(ap(ap(map(f) (tw)) (tx)) (ty)) (tz);
  
liftA4({map: arrMap, ap: arrAp})
  (w => x => y => z => [w, x, y, z])
    ([1, 2])
      (["a", "b"])
        ([true, false])
          ([[], {}]); // [[1, 'a', true, []], ...]
```
[run code](https://repl.it/repls/WhirlwindLightcyanEmacs)

`liftA4` applied to four arrays yields the cartesian product of the involved arrays in form of an array of 4-tuples. The combinator works with any applicative functor. Let us drop the type class constraints and rearrange/rename a few arguments to direct the attention to the essential computational structure:

```javascript
const apply4 = v => f => w => g => x => h => y => i => z =>
  i(h(g(f(v) (w)) (x)) (y)) (z);

const applyr4 = v => f => w => g => x => h => y => i => z =>
  f(v) (g(w) (h(x) (i(y) (z))));

const sub = x => y => x - y;

apply4(1)
  (sub) (2)
    (sub) (3)
      (sub) (4)
        (sub) (5); // ((((1 - 2) - 3) - 4) - 5) === -13

applyr4(1)
  (sub) (2)
    (sub) (3)
      (sub) (4)
        (sub) (5); // (1 - (2 - (3 - (4 - 5)))) === 3

```
[run code](https://repl.it/repls/EverlastingTechnoSymbols)

An applicative computation is just the left-associative variant to compose binary functions in a meaningful way. In a subsequent chapter we will see that there is another meaningful way to compose binary function, the monadic way.

### Order of applicative computations

Applicative does not rely on the result of the previous applicative computation. As a consequence such computations do not necessarily rely on a specific order, as long as the effects of both contexts are performed exactly once. Given this there are two distinct ways of combining two applicative contexts: in-sequence or in-parallel. Even though an applicative computation is static in terms of its contexts we cannot always determine at compile time in what order they are evaluated.

### Applicative laws

These are the laws every applicative instance must abide by:

```
~ denotes equivalence
f denotes a pure function
x denotes a pure value
tx denotes a value in an applicative context

ap(of(id)) (tx) ~ tx // identity
ap(of(f)) (of(x)) ~ of(f(x)) // homomorphism
ap(tx) (of(y)) ~ ap(of(f => f(y))) (tx) // interchange
ap(ap(ap(of(comp)) (tx)) (ty)) (tz) ~ ap(tx) (ap(ty) (tz)) // composition
```
### `Option` instance

If the effect an applicative context has on its value(s) must be performed exactly once does this mean we cannot short circuit an applicative computation? Strictly speaking yes, unless the instance implementation of `ap` itself provides this ability:

```javascript
const Option = union("Option");

const None = Option("None", {});
const Some = some => Option(Some, {some});

// functor

const optMap = f => tx =>
  match(tx, {
    None: _ => None, // short circuiting
    Some: ({some: x}) => Some(f(x))
  });

// applicative

const optOf = x => Some(x);

const optAp = tf => tx =>
  match(tf, {
    None: _ => None, // short circuiting
    Some: ({some: f}) => {
      return match(tx, {
        None: _ => None, // short circuiting
        Some: ({some: x}) => Some(f(x))
      });
    }
  });

const comp = f => g => x => f(g(x));
const add = x => y => x + y;

comp(optAp) (optMap(add)) (Some(2)) (Some(3)); // Some(5)
comp(optAp) (optMap(add)) (None) (Some(3)); // None
```
[run code](https://repl.it/repls/CyanCuddlyOrganization)

With the `Option` type, whenever the computation comes upon the `None` case, no matter at what position, the whole applicative computation is short circuited and the pure function (namely `add`) never evaluated. `Option` captures computations that may not yield a result at all. It makes this effect explicit and forces you to always handle both cases when dealing with such computations.

### Function instance

`ap` of the function instance does not include short circuiting, hence we cannot break out of such a computation. The function applicative supplies the notion of a computation with a read-only environment. It is a special case because the context is just function application:

```javascript
const comp = f => g => x => f(g(x));

const _const = x => _ => x;

const funMap = comp;

const funOf = _const;

const funAp = tf => tg => x =>
  tf(x) (tg(x));

const add = x => y => x + y;
const sqr = x => x * x;

funAp(funMap(add) (sqr)) (sqr) (3); // 9 + 9 == 18
funAp(add) (sqr) (3); // 9 + 3 == 12
```
[runccode](https://repl.it/repls/NiftyColossalRar)

With functions we do not need the applicative pattern but can provide the bare function to `ap`. Does not this break the rule? No, because `ap` expects a value wrapped in a context. Our value is an unary function `y => x` and the context is another function layer, that is, a curried function `x => y => x`. A binary curried function is enough. If we ignore the second argument we get `_const`, which happens to be `of`, because it is the most minimal context of the function instance.

In the example above we used predefined arithmetic functions to build an applicative computation. Usually we use a lambda:

```javascript
const liftA4 = ({map, ap}) => f => tw => tx => ty => tz =>
  ap(ap(ap(map(f) (tw)) (tx)) (ty)) (tz);

const id = x => x;
const inc = x => x + 1;
const neg = x => -x;
const sqr = x => x * x;

liftA4({map: funMap, ap: funAp})
  (w => x => y => z => [w, x, y, z])
    (id)
      (neg)
        (inc)
          (sqr)
            (3); // [3, -3, 4, 9]
```
[run code](https://repl.it/repls/NoteworthyLovingCode)

No matter what we do we cannot break out of the applicative computation:

```javascript
liftA4({map: funMap, ap: funAp})
  (w =>
    w === 0
      ? _ => _ => _ => [] // we still have to go through the entire computation
      : x => y => z => [w, x, y, z])
        (id)
          (neg)
            (inc)
              (sqr)
                (0); // []
```
[run code](https://repl.it/repls/DarkseagreenQuixoticPi)

### Applicatives compose

Since applicatives are functors they compose, i.e. we can compose contexts and their effects. I want to take the chance and demonstrate on the following a bit more complex example the process of abstracting in functional programming. We start with the most detailed encoding and then try to abstract from boilerplate and common patterns.

When we combine composed/nested applicatives like `Task(Some([1, 2, 3]))` and `Task(Some([4, 5, 6]))`, we have to deal with the applicative pattern `ap(map(f) (x)) (y)`, which renders the process quite complex and confusing:

```javascript
tAp(
  tMap(x => y =>
    optAp(
      optMap(x_ => y_ =>
        arrAp(
          arrMap(add) (x_)) (y_)) (x)) (y));
```
This is the applicative operation to handle an async computation that may fail or yields any number of results. We can get rid of the lambdas by using point-free style:

```javascript
tAp(
  tMap(
    comp(optAp)
      (optMap(
        comp(arrAp)
          (arrMap(add)))));
```
This encoding reveals the applicative pattern. We can use the `liftA` function family to abstract from it:

```javascript
comp3(
  tLiftA2)
    (optLiftA2)
      (arrLiftA2)
        (add);
```
The above implementation is pretty easy to read. Let us put everything together to see how it works:

```javascript
// polymorphic lift

const liftA2 = ({map, ap}) => f => tx => ty =>
  ap(map(f) (tx)) (ty);

// TASK

const Task = task => record(
  Task,
  thisify(o => {
    o.task = (res, rej) =>
      task(x => {
        o.task = k => k(x);
        return res(x);
      }, rej);
    
    return o;
  }));

// Functor

const tMap = f => tx =>
  Task((res, rej) => tx.task(x => res(f(x)), rej));

// Applicative

const tOf = x => Task((res, rej) => res(x));

const tAp = tf => tx =>
  Task((res, rej) =>
    tf.task(f =>
      tx.task(x => res(f(x)), rej), rej));

const tLiftA2 = liftA2({map: tMap, ap: tAp});

// OPTION

// Applicative

const optLiftA2 = liftA2({map: optMap, ap: optAp});

// ARRAY

// Applicative

const arrLiftA2 = liftA2({map: arrMap, ap: arrAp});

// auxiliary functions

const thisify = f => f({});
const comp3 = f => g => h => x => f(g(h(x)));

// MAIN

const tttx = tOf(optOf([1, 2, 3])),
  ttty = tOf(optOf([10, 20, 30])),
  tttz = tOf(None);

const main = comp3(
  tLiftA2)
    (optLiftA2)
      (arrLiftA2)
        (add)
          (tttx)
            (ttty);

const main2 = comp3(
  tLiftA2)
    (optLiftA2)
      (arrLiftA2)
        (add)
          (tttx)
            (tttz);

main.task(x => x); // Task(Some([11, 21, 31, 12, 22, 32, 13, 23, 33]))
main2.task(x => x); // Task(None)
```
[run code](https://repl.it/repls/ValidBlushingVolume)

As you can see we are able to combine two composed contexts/effects with `main`/`main2` and everything works as expected.

### Applicative monoids

* an applicative that has a monoid for its type variable is also a monoid

instance (Applicative f, Semigroup a) => Semigroup (Ap f a) where
        (Ap x) <> (Ap y) = Ap $ liftA2 (<>) x y

instance (Applicative f, Monoid a) => Monoid (Ap f a) where
        mempty = Ap $ pure mempty

### Note on my own account

If you enjoyed this chapter please ðŸŒŸ the repo here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.
