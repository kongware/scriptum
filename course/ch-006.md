## Lazy Evaluation on Demand

**[Editor's note: this chapter is currently being edited]**

Lazy evaluation means that expressions are evaluated

* only when needed
* just enough
* only once

The next sections will discuss each point in detail.

#### Normal order evaluation

Applicative order is the common evaluation strategy of imperative and multi-paradigm languages. It evaluates all subexpressions passed to a function as its arguments right before the function is called.

Normal order evaluation passes argument subexpressions to functions as they are and proceeds with their evaluation only if the results are actually needed within the function body:

```javascript
// hypothetical normal evaluation order in Javascript

const add = x => y => x + y;

const foo = add(2 + 3) (4 * 5); // A
//              ^^^^^   ^^^^^ subexpressions
const main = foo + 0; // B
```
With normal evaluation order both subexpressions are not evaluated but passed to `add` as is (line `A`). However, in line `B` the evaluation is forced, because the result of the addition is needed. Let us further look into the evaluation process:

```javascript
foo + 0

// first add's body is inlined with the unevaluated arguments

((2 + 3) + (4 * 5)) + 0

// then the resulting expression is further reduced to normal form

(5 + 20) + 0
25 + 0
25 // normal form
```
#### Weak Head Normal Form (WHNF)

Lazy evaluation also means to evaluate subexpressions just enough, that is to pause evaluation as early as possible. An expression need not to be further reduced when the outermost level is a lambda abstraction. Such an expression is in WHNF, that is it may contain unevaluated subexpressions referred to as thunks. Taking the above example the add function call is in WHNF:

```javascript
// hypothetical WHNF in Javascript

// WHNF

add(2 + 3) (4 * 5)
add(2 + 3)

// not in WHNF

add(2 + 3) (4 * 5) + 1
```
The expression in the last line is not in WHNF, because the outermost level is not a lambda abstraction but the `+` operator with two operands. Hence the expressions require further reduction. Since the `+` operator eagerly requires both operands to be fully evaluated the preceding `add` function call is forced to normal form.

#### Sharing

Lazy evaluation would be very inefficient if it had to evaluate the same subexpression each time it occurs in a function body. For that reason the result of once evaluated subexpressions is stored and shared within the same scope:

```javascript
const foo = x => [
  x + x,
  x - x,
  x * x];

foo(2 + 3);
```
The invocation of `foo` triggers the evaluation of `2 + 3` only once, even though it is used six times.

### Lambda abstractions

As we have seen lazyness defers the evaluation of subexpressions. When we squint hard enough this also applies to ordinary functions, because they are only evaluated when the required arguments are provided. This inherently lazy behavior allows us to partially apply them:

```javascript
const add = x => y => x + y,
  add2 = add(2);
```
#### Eta abstractions

`f` and `x => f(x)` are not the same when it comes to evaluation in an eagerly evaluated language like Javascript. The latter renders a function slightly lazier:

```javascript
const foldMap = f => acc => ix => {
  for (let [i, x] of ix)
    acc = f(acc) (x);

  return acc;
};

const arrSnoc = xs => x =>
  (xs.push(x), xs);

const mapToArr =
  foldMap(arrSnoc) ([]);

const mapToArr_ = ix =>
//                ^^
  foldMap(arrSnoc) ([]) (ix);
//                      ^^^^

const foo = new Map([[0, "foo"], [1, "bar"], [2, "baz"]]);

mapToArr(foo);
mapToArr_(foo);

mapToArr(foo); // ["foo", "bar", "baz", "foo", "bar", "baz"]
mapToArr_(foo); // ["foo", "bar", "baz"]
```
[run code](https://repl.it/@scriptum/MeanNoxiousChord)

`mapToArr` gets a fresh array as accumulator each time it is called and hence keeps the side effect caused by `arrSnoc` local. Adding redundant lambda abstractions to a derived function is called eta abstraction and the opposite operation eta reduction.

#### Function composition

You can think of function composition as the introduction rule of the function type. If you compose two existing functions you create a new one. Since functions are inherently lazy you can dynamically create new lazy types exhibiting new lazy behavior:

```javascript
const comp = f => g => x => f(g(x));
const flip = f => y => x => f(x) (y);

const inc = x => x + 1;
const strRepeat = n => s => s.repeat(n);

const main = comp(
  flip(strRepeat) ("Hi"))
    (inc);

// nothing evaluated yet

main(2); // "HiHiHi"
```
[run code](https://repl.it/@scriptum/WebbedDryDiskdrive)

#### Continuation passing style

Can we defer the function application even further?

```javascript
const compk = f => g => x => k =>
  k(f(g(x)));
//  ^^^^^^^ deferring effect

const inc = x => x + 1;

const sqr = x => x * x;

const id = x => x;

const main = compk(
  sqr) (inc) (4);

// main is still unevaluated

main(id); // 25
```
[run code](https://repl.it/@scriptum/AppropriateBestObjectmodel)

CPS is a function encoding and allows us to control the rest of the computation and thus literally the rest of the program. This way we are able to compose arbitrarily complex compositions, which are technically nested function call trees. We will learn about continuation passing style in a subsequent chapter of this course.

### Description of computations

Function call trees are deferred function applications that are only evaluated when the initial value is provided. When we construct such computations we neither need to provide a value nor evaluate the computation in place. We defer it and still add types and new behavior layer by layer.

What is a proper notion of such a computation? It is not a normal computation anymore but a description of a computation. Since function call trees are just nested functions which are just functions which are ordinary values we can pass them around like data. We create and pass around descriptions of computations and it is up to the consumer of these structures to provide the necessary value to actually evaluated them.

### From nullary functions to implicit thunks

Using the inherent lazyness of functions for our own benefit is a very powerful technique and one of the major effects that the paradigm has on your code. However, we would like to have a more fine-grained control over the evaluation time of an arbitrarily expression. Javascript pursues an eager evaluation strategy, that is, we need to mimic lazyness somehow. The usual approach is to utilize nullary functions for that matter:

```javascript
const comp = f => g => x =>
  () => f(g(x));
  ^^ nullary function
```
Nullary functions are also referred to as thunks in Javascript. The type affects the call side though, because the consumer of such code needs to apply the thunk accordingly, even though there is no argument. Can we render lazy evaluated code more natural in a setting with strict semantics? We can indeed, provided we are willing to intercept property accesses and functions calls with the `Proxy` interface:

```javascript
// implicit thunks (simplified version)

const thunk = f =>
  new Proxy(f, new ThunkProxy());

const strict = thunk => {
  while (thunk && thunk[THUNK])
    thunk = thunk.valueOf();

  return thunk;
};

class ThunkProxy {
  constructor() {
    this.memo = undefined;
  }

  get(g, k) {
    if (this.memo === undefined) {
      this.memo = g();
      
      while (this.memo && this.memo[THUNK])
        this.memo = this.memo.valueOf();
    }

    if (k === THUNK)
      return true;

    else if (k === Symbol.toPrimitive)
      return this.memo[Symbol.toPrimitive];

    else if (k === "valueOf")
      return () => this.memo;

    else return this.memo[k];
  }
}

// auxiliary functions

const taggedLog = tag => x =>
  (console.log(tag, x), x);

const add = x => y =>
  thunk(() => taggedLog("add") (x + y));

const mul = x => y =>
  thunk(() => taggedLog("mul") (x * y));

// MAIN

const main = add(add(2) (3)) (mul(4) (5)); // WHNF
//               ^^^^^^^^^^   ^^^^^^^^^^ not immediately evaluated

// nothing logged yet!

// enforce evaluation
strict(main); // logs 5, 20, 25 and yields 25
```
[run code](https://repl.it/@scriptum/FarawayImmediateSyntax)

Please note that this is essentially the example from the beginning of this chapter but the presumably lazily evaluated version. Is this full-fledged lazyness? Let us verify whether we meet all requirements, namely normal order, WHNF and sharing, before we get too excited:

```javascript
// auxiliary functions

const taggedLog = tag => x =>
  (console.log(tag, x), x);

const add = x => y =>
  thunk(() => taggedLog("2 add 3 =") (x + y));

const mul = x => y =>
  thunk(() => taggedLog("5 mul 5 =") (x * y));

const foo = x => [
//Ë… here x is actually evaluated (A)
  x + x,
//    ^ here x is shared (C)
  x - x,
//^   ^ here x is shared (C)
  mul(x) (x)];
  ^^^^^^^^^^ only evaluated when needed
  
// MAIN

const r = add(2) (3); // thunk

// add is still an unevaluated thunk

const main = foo(r); // logs "2 add 3 = 5" and yields [10, 0, thunk]
//           ^^^^^^ WHNF (B)

// mul is still an unevaluated thunk

// enforce evaluation
strict(main[2]); // logs "5 mul 5 = 25" and yields 25
```
[run code](https://repl.it/@scriptum/EasygoingUnhealthyAttribute)

`foo` evaluates its argument `add(2) (3)` only when needed (`A`), that is, when its result is used the first time within `foo`. `main` is in WHNF (`B`), because it contains an unevaluated thunk. `foo` evaluates `add(2) (3)` only once and shares the result (`C`). We have achieved proper lazy evaluation in Javascript. This is huge! Let us discover some use cases for our lazy evaluation on demand strategy.

***

#### Guarded recursion

If you pass a reducing functon to fold that is lazy in its second argument, you get stack safety for free:

```javascript
// ARRAY

const arrFoldr_ = f => acc => xs => {
  const go = i =>
    i === xs.length
      ? acc
      : f(xs[i]) (thunk(() => go(i + 1)));

  return go(0);
};

const arrTake = n => xs => {
  const go = (acc, [y, ys]) =>
    y === undefined || acc.length === n
      ? acc
      : go(arrSnoc(y) (acc), ys);

  return go([], xs);
};

const arrSnoc = x => xs => (xs.push(x), xs);
const arrCons = head => tail => [head, tail];

// auxiliary functions

const add = x => y => x + y;

// MAIN

const xs = Array(1e5)
  .fill(0)
  .map((_, i) => i + 1);

const main = arrFoldr_(arrCons) ([]) (xs), // stack safe due to lazyness
  main2 = arrFoldr_(add) ([]) (xs); // stack overflow

arrTake(3) (main); // [1, 2, 3]
```
[run code](https://repl.it/@scriptum/ShadowyFlimsySmalltalk)

This effect of lazy evaluation is referred to as guarded recursion. It is equivalent with the tail call modulo cons optimization in eager languages. `main2` is not stack safe, because `add` is strict in both of its arguments. We would use a normal left associative instead, which either benefits from tail call optimization or relies on a trampoline.

#### Infinite recursion

Lazy evaluation enables infinite recursions of otherwise non-terminating algorithms. This kind of recursion allows implementations which can be expressed more natural and succinct than with finite recursion in some cases:

```javascript
const fix = f => thunk(() => f(fix(f)));

const fact = fix(go => n =>
  n === 0
    ? 1
    : n * go(n - 1));

fact(5); // 120
```
[run code](https://repl.it/@scriptum/MurkyDetailedAutosketch)

The Fibonacci numbers as an infinite stream:

```javascript
const fibs = [0, [1, thunk(() => {
  const next = ([x, [y, ys]]) =>
    [x + y, thunk(() => next([y, ys]))];

  return next(fibs);
})]];

fibs[1] [1] [1] [1] [1] [1] [1] [1] [1] [1] [0]; // 55
```
[run code](https://repl.it/@scriptum/WiltedDarkseagreenCoolingfan)

#### Incremental algorithms

Eagerly evaluated languages need iterators to lazily traverse a data structure. In a lazy evaluated setting we can operate incrementally on streams of data for free:

```javascript
// union constructor

const union = type => (tag, o) =>
  (o[type] = type, o.tag = tag.name || tag, o);

const match = (tx, o) =>
  o[tx.tag] (tx);

// LIST

const List = union("List");

const Nil = List("Nil", {});

const Cons = head => tail =>
  List(Cons, {head, tail});

const listFoldr_ = f => acc => {
  const go = xs =>
    match(xs, {
      Nil: _ => acc,
      Cons: ({head, tail}) => f(log(head)) (thunk(() => go(tail)))
    });

  return go;
};

// ARRAY

const arrTake = n => xs => {
  const go = (acc, {head, tail}) =>
    head === undefined || acc.length === n
      ? acc
      : go(arrSnoc(head) (acc), tail);

  return go([], xs);
};

const arrSnoc = x => xs => (xs.push(x), xs);

// auxiliary functions

const comp = f => g => x => f(g(x));

const map = f => append => x => acc =>
  append(f(x)) (acc);

const filter = p => append => x => acc =>
  p(x)
    ? append(x) (acc)
    : acc;

const transduce = ({append, fold}) => f =>
  fold(f(append));

const getLen = xs => xs.length;

const sqr = x => x * x;

const sqrLen = comp(sqr) (getLen);

const isEven = x => (x & 1) === 0;

const log = x => (console.log(x), x);

// MAIN

const xs = Cons("f") (
  Cons("fo") (
    Cons("foo") (
      Cons("fooo") (
        Cons("foooo") (
          Cons("fooooo") ( // A
            Cons("foooooo") (
              Cons("fooooooo") (
                Cons("foooooooo") (
                  Cons("fooooooooo") (Nil))))))))));

const main = transduce({append: Cons, fold: listFoldr_})
  (comp(map(sqrLen))
    (filter(isEven)))
      (Nil)
        (xs);

// main is not evaluated yet

arrTake(2) (main); // [4, 16]
```
[run code](https://repl.it/@scriptum/JuvenileWhimsicalWatchdog)

The lazy right associative fold acts like a stream. We must pull each single value out of the data structure, so it does not matter if it is infinite. Short circuiting just means to stop pulling. In our example the iteration stops at line `A`, because at this point the algorithm knows that it has accumulated sufficient values. The transducer allows us to fuse both operations, mapping and filtering, into a single one, in order to traverse the `List` only once.

#### Separating declaration from production

In general, the common theme here is that with lazily evaluated infinite data structures you can separate the declaration of a structure from the production of its contained values. The production is only triggered by the determination of which values are interesting to look at. This makes things more composable, because the choice of what is interesting to look at need not be known by the producer. You can certainly imagine that lazy evaluation exhibits many more meaningful use cases than demonstrated in this chapter. It is a vast field.

#### Enforcing evaluation

If we use functions with result expressions in WHNF, we sometimes need a means to enforce evaluation. This is the purpose of the `strict` combinator, which also handles arbitrarily nested thunks:

```javascript
const THUNK = "thunk";

const strict = thunk => {
  while (thunk[THUNK])
    thunk = thunk.valueOf();

  return thunk;
};
```
### Editor's note

If you enjoyed this chapter please ðŸŒŸ scriptum here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/course/ch-005.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc) | [next chapter &gt;](https://github.com/kongware/scriptum/blob/master/course/ch-007.md)
