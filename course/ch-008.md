## From Recursion to Corecursion

Recursion and corecursion are dual to one another. Recursion operates on data and likewise corecursion operates on codata. While you can encode all iterative algorithms recursively, corecursion sometimes leads to more natural and succinct implementations. In most programming languages both approaches are not distinguished on the type level and neither are data and codata. In this chapter, however, I will delineate recursion from corecursion in order to gain a deeper understanding of both concepts. This is particularly useful to determine when to apply which approach.

### The structure of recursion

Recursion embodies the idea of recurrent function application like `f(f(...f(x)))`, where the number of applications is not known upfront. Such a function application is non-deterministic, because the number of invocations can only be determined at runtime.

A recursive algorithm consists of one or more recursive steps and one or more base cases. A base case is the smallest or simplest instance of a data chunk, which cannot be decomposed any further. A recursive step decomposes a larger instance of a data chunk into one or several simpler or smaller instances. The recursive algorithm either implicitly uses the function call stack or builds up a custom stack-like structure on the way forward to the base case. When it has passed the base case the function call or the custom stack is unwind on the way back and the intermediate results are recomposed to syntathize the solution to the original problem.

### Body and tail recursion

You can distinguish recursion by the lexical position of the recursive step within the function body. If it is the last operation, it is in tail otherwise in non-tail or body position. Both forms are therefore referred to as tail and non-tail or body recursion. Body recursion keeps state in the implicit function call stack, whereas tail recursion keeps it in an explicit data structure, which serves as a substitute of the call stack. This data structure is often called accumulator.

As a consequence a body recursive algorithm builds its result from the way back from the base case, whereas a tail recursive one builds its result on the way forward from the initial case. The following examples illustrate both approaches:

```javascript
const log = x => (console.log(x), x);

// body recursive

const fibBody = n =>
  n > 1
    ? fibBody(n - 1) + fibBody(n - 2) // recursive step + implicit function call stack
    : log(n); // base case

// tail recursive

const fibTail = n => {
  const go = (x, acc, m) =>
    m > 1
      ? go(acc, acc + x, m - 1) // recursive step + explicit accumulator
      : log(acc); // base case

  return go(0, 1, n);
};

fibBody(10); // logs 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0

fibTail(10); // logs 55
```
[run code](https://repl.it/@scriptum/LimpingAromaticModule)

In the above example we log at the base case in order to reveal the internal control flow. Since the body recursive Fibonacci algorithm decomposes the problem to the smallest and simplest instances on the way forward to the base case, an exponentially growing number of `1` and `0` are logged. Evidently this is quite inefficient.

The tail recursive algorithm on the other hand starts its work right away from the initial case. Consequently it has already finished its work when the underlying data is consumed and only the final result is logged. Let us visualize the progress by logging the accumulator instead:

```javascript
const fibTail = n => {
  const go = (x, acc, m) =>
    m > 1
      ? (log(acc), go(acc, acc + x, m - 1))
      : log(acc);

  return go(0, 1, n);
};

fibTail(10); // logs 1, 1, 2, 3, 5, 8, 13, 21, 34, 55
```
[run code](https://repl.it/@scriptum/PiercingLimitedOmnipage)

Since body recursion depends on the function call stack the problem size that can be handled is limited to the available stack size. In contrast to this tail recursion can share a single stack frame throughout the entire computation, because the accumulator assumes the role of the stack frame and provided the language pursues tail call elimination. Technically tail recursion is the functional equivalent of imperative loops. However, for body recursion an imperative loop is not sufficient. It takes an additional custom call stack structure to render it equally expressive.

What else distinguishes body from tail recursion? Let us use a simplified single linked list to get an insight:

```javascript
// body recursive

const foldr = f => acc => ([h, t]) =>
  h === undefined
    ? acc
    : f(h) (foldr(f) (acc) (t));

// tail recursive

const foldl = f => acc => ([h, t]) =>
  h === undefined
    ? acc
    : foldl(f) (f(acc) (h)) (t);

const sub = x => y => x - y;

const xs = [1, [2, [3, []]]];

foldr(sub) (0) (xs); // (1 - (2 - (3 - 0))) = 2
foldl(sub) (0) (xs); // (((0 - 1) - 2) - 3) = -6
```
[run code](https://repl.it/@scriptum/DimJauntyApplet)

Obviously body recursion along with a binary operation forms a right associative fold, whereas tail recursion forms a left associative one. As a matter of fact you cannot transform one into the other in a pure way without reversing the result list.

### Primitive recursion

Primitive (or natural) recursion is a form of recursion where at each iteration the original data chunk is decomposed by its smallest or simplest possible instance(s). This limitation ensures that every recursive algorithms terminates, because it is guaranteed to hit the base case at some point:

```javascript
// Array
([x]) => x;

// natural numbers
n => n - 1;
```
Both operations will ultimately reach the base case, which is the empty array or zero in the above instances. Next comes a primitive recursive arithmetic functions that operates on natural numbers:

```javascript
// power sequence

const natPow = x => n => {
  const go = (m, r) =>
    m <= 0
      ? r
//      ^
      : go(m - 1, x * r);
//         ^^^^^^^^^^^^

  return go(n, 1)
};

// factorial sequence

const natFact = n => {
  const go = (m, [x, y]) =>
    m <= 0
      ? y
//      ^
      : go(m - 1, [x + 1, (x + 1) * y]);
//         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  return go(n, [0, 1]);
};

// fibonacci sequence

const natFib = n => {
  const go = (m, [x, y]) =>
    m <= 0
      ? x
//      ^
      : go(m - 1, [y, x + y]);
//         ^^^^^^^^^^^^^^^^^

  return go(n, [0, 1]);
};

// MAIN

natPow(2) (8); // 256
natFact(5); // 120
natFib(10); // 55
```
[run code](https://repl.it/@scriptum/BetterGoldenCommunication)

As you can see these algorithms differ only in two sections at the same lexical positions. If we abstract from the rest, the underlying structure is revealed, which is called a catamorphism in functional programming. You can think of a catamorphism as a slightly generalized fold:

```javascript
// auxiliary functions

const comp = f => g => x => f(g(x));
const fst = ([x, _]) => x;
const snd = ([_, y]) => y;

// NATURAL NUMBERS

// catamorphism

const natCata = zero => succ => {
  const go = n =>
    n <= 0
      ? zero
      : succ(go(n - 1));

  return go;
};

// instances

const pow = x =>
  natCata(1) (n => n * x);

const fact = comp(snd)
  (natCata([0, 1]) (([x, y]) => [x + 1, (x + 1) * y]));

const fib = comp(fst)
  (natCata([0, 1]) (([x, y]) => [y, x + y]));

// MAIN

pow(2) (8); // 256
fact(5); // 120
fib(10); // 55
```
Please note that there are catamorphisms for many data types, not only for natural numbers. We can further generalize and gain a polymorphic catamorphism using a functor algebra. We will learn about this concept in a later chapter of this course.

Unfortunately, this is still not the end of the story. Strictly speaking primitive recursion corresponds to a paramorphism not to a catamorphism. The former is a more convenient form of the latter, but theoretically equally expressive. A paramorphism has access to the intermediate state of the value to be folded, i.e. the partially folded value. This feature allows more natural implementations for some recursive algorithms:

```javascript
// NATURAL NUMBERS

// catamorphism

const natPara = zero => succ => {
  const go = n =>
    n <= 0
      ? zero
      : succ(go(n - 1)) (n);
//                      ^^^ provides the state of the value to be folded

  return go;
};

// instances

const fact = natPara(1) (x => y => x * y); // more natural

const fib = comp(fst)
  (natPara([0, 1]) (([x, y]) => _ => [y, x + y])); // no improvement

fact(5); // 120
fib(10); // 55
```
[run code](https://repl.it/@scriptum/SkeletalGrownBoastmachine)

### Indirect or mutual recursion

If `foo` calls `bar`, which calls `bat`, which in turn calls `foo` then all three involved functions form a recursive algorithm, an indirectly recursive one to be precise. The following example is not very efficient and rather contrived but serves the purpose to illustrate this mechanism:

```javascript
const fibChild = n =>
  n < 1
    ? 1
    : fib(n - 1);

const fib = n =>
  n < 1
    ? 0
    : fib(n - 1) + fibChild(n - 1);

fib(10); // 55
```
[run code](https://repl.it/@scriptum/FlippantRedundantVisitor)

Indirect recursion allows very elegant algorithms when working with tree data structures. We will look into such algorithms in the corresponding chapter of this course.

### Anonymous recursion

The `fix` combinator allows anonymous recursion by supplying the recursive term as a function argument:

```javascript
const fix = f => x => f(fix(f)) (x);

const fib = fix(go => n =>
  n > 1
    ? go(n - 1) + go(n - 2)
    : n);

fib(10); // 55
```
[run code](https://repl.it/@scriptum/SlategrayWiryBoolean)

While `fix` provides an elegant API, it is not tail recursive and hence not stack safe. In the next chapter we will see that trampolines are a more viable alternative.

### Corecursion and codata

In most functional languages there is no distinction between recursion on data on the one hand and corecursion on codata on the other. I am going to make this distinction anyway, because it helps to get a better intuition of both concepts.

Corecursion is dual to recursion. While recursion means to call oneself on smaller data chunks at each iteration until the smallest possible data chunk is reached, corecursion means to call oneself on data chunks at each iteration that are greater than or equal to what one had before. Recursion recomposes the data chunks on the way back from the base case. Corecursion already composes data chunks on the way forward by constantly expanding the initial value:

```javascript
// implicit thunk

const thunk = f =>
  new Proxy(f, new ThunkProxy());


class ThunkProxy {
  constructor() {
    this.memo = undefined;
  }

  get(g, k) {
    if (this.memo === undefined) {
      this.memo = g();
      
      while (this.memo && this.memo[THUNK])
        this.memo = this.memo.valueOf();
    }

    if (k === THUNK)
      return true;

    else if (k === Symbol.toPrimitive)
      return this.memo[Symbol.toPrimitive];

    else if (k === "valueOf")
      return () => this.memo;

    else return this.memo[k];
  }
}

const THUNK = "thunk";

// corecursion

const fibs = [0, [1, thunk(() => {
  const go = ([x, xs], [y, ys]) =>
    [x + y, thunk(() => go(xs, ys))];

  return go(fibs, fibs[1]);
})]];

// MAIN

fibs[1] [1] [1] [1] [1] [1] [1] [1] [1] [1] [0]; // 55
```
[run code](https://repl.it/@scriptum/SuperiorAdolescentType)

This is bare corecursion in its original form, because we work directly within the literal of the given type. A more abstract corecursive encoding can be defined using the well-known `iterate` function:

```javascript
// auxiliary function

const map = f => ([x, xs]) =>
  [f(x), thunk(() => map(f) (xs))];

const fst = ([x, _]) => x;

// corecursion

const iterate = f => x =>
  [x, thunk(() => iterate(f) (f(x)))];

const fibs = map(fst)
  (iterate(
    ([x, y]) => [y, x + y])
      ([0, 1]));

// MAIN

fibs[1] [1] [1] [1] [1] [1] [1] [1] [1] [1] [0]; // 55
```
[run code](https://repl.it/@scriptum/CyberFeistyNumbers)

Corecursion defines values in terms of itself, which are potentially infinite. As opposed to recursion a corecursive algorithm must not terminate and thus depends on lazy evaluation. It starts with the base case as a seed and expands this seed on the way forward. You can think of recursion as a set of algorithms that consume data up to the base case. In contrast to this corecursion produces data beginning with the base case. This describes the duality between both concepts pretty good. Recursion is analytical whereas corecursion is synthetical.

Maybe you have noticed that corecursion looks a lot like tail recursion. Just as with tail recursion corecursion uses an accumulator and produces its result on the way forward. However, corecursion relies on lazy evaluation, because it encodes the idea of potentially infinite data streams. Lazy evaluation has the additional characteristics that it allows every iterative algorithm to be short circuited during each iteration.

#### Codata

In intuitive terms, a data type is a way of representing any construction of a list-like object, while a codata type is a way of representing any destruction of a list-like object. Data is produced by a finite number of constructor applicatations. Codata is consumed by a finite number of pattern matches (destructor applications). In languages where data and codata are different, there is a fundamental asymmetry. A terminating program can only construct a finite list, but it can destruct a discrete part of an infinite list. So data must be finite, but codata can be finite or infinite.

An infinite lazy list, for instance, is similar to a stream. It is introduced by corecursively applying the constructor and eliminated by recursively matching patterns. The latter only works in a setting with strict evaluation semantics though:

```javascript
// corecursion

const fibs = [0, [1, thunk(() => {
  const go = ([x, xs], [y, ys]) =>
    [x + y, thunk(() => go(xs, ys))];

  return go(fibs, fibs[1]);
})]];

// recursion

const mapEager = f => ([x, xs]) =>
  [f(x), mapEager(f) (xs)];

const mapLazy = f => ([x, xs]) =>
  [f(x), thunk(() => mapLazy(f) (xs))];

// auxiliary function

const arrTake = n => xs => {
  const go = (acc, [head, tail]) =>
    head === undefined || acc.length === n
      ? acc
      : go(arrSnoc(head) (acc), tail);

  return go([], xs);
};

const arrSnoc = x => xs =>
  xs.concat([x]);

const inc = x => x + 1;

// MAIN

try {mapEager(inc) (fibs)}
catch(e) {console.log(e.message)} // stack overflow

arrTake(10)
  (mapLazy(inc)
    (fibs)); // [1, 2, 2, 3, 4, 6, 9, 14, 22, 35]
```
[run code](https://repl.it/@scriptum/LimpingGlumMathematics)

So usually codata cannot be processed with recursion, unless the recursive algorithm itself is lazy.

### Recursion as a last resort

Recursion und corecursion are functional primitives. Functional programmers usually prefer I higher level of abstraction to work with. Abstractions are a mixed blessing though: On the one hand they spare us a lot of details and reduce the mental load. But on the other hand you have to be familiar with these abstractions and be trained how to handle them effectively. Let us illustrate the issue by taking another look at the corecursive `fibs` function:

```javascript
const fibs = [0, [1, thunk(() => {
  const go = ([x, xs], [y, ys]) =>
    [x + y, thunk(() => go(xs, ys))];

  return go(fibs, fibs[1]);
})]];
```
We can streamline the algorithm by using a fold abstraction:

```javascript
const fibs = unfoldr(
  ([x, y]) => Some([x, [y, x + y]])) ([0, 1]);
```
You can only comprehend this abstraction if you are familiar with `unfoldr` or unfolding in general, of course. And applying it yourself takes even more experience. However, when you are an experienced functional programmer you will highly appreciate a certain level of abstraction, because it spares you a lot of distracting details and unnecessary boilerplate.

Bottom line recursion and corecursion are a last resort that we sometimes need when we have to deal with a very specific problem or rely on micro optimizations for a performance critical portion of our program. Otherwise we try to avoid the low level work and appreciate the blessing of higher abstractions.

### Editor's note

If you enjoyed this chapter please ðŸŒŸ scriptum here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/course/ch-007.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc) | [next chapter &gt;](https://github.com/kongware/scriptum/blob/master/course/ch-009.md)
