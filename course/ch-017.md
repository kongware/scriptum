## Combining Effects with Actions using Monad

### The limitation of applicative

In the chapter about applicatives we have learned that the next applicative effect may depend on a previous one but we cannot determine the next effect depending on a previous dynamically evaluated value. It turns out that despite this limitation applicative computations are applicable for a surprising number of cases. They are not always enough though. We need a slightly less general, slightly more expressive alternative.

Please note that when we are talking about effects we do not mean side effects but all other computational effects.

### Extending `Applicative` by `Monad`

Provided you have understood applicative functors it is only a small step to comprehend monads:

_Monads have essentially the purposes to overcome the limitation of applicatives._

This also means that you always should attempt to use applicatives first. Only if you cannot express something with this algebraic structure you should resort to the extra power of monads, because such power always entails its very own drawbacks. During this chapter we will come across some. There is also a common misunderstanding in connection with them:

_Monads are no means to handle I/O._

A purely functional language ships with a special type baked into its core to handle I/O and to connect the pure realm of the language with the real world during compilation. Monads as well as applicatives are merely a means to combine computations of this type. This does not hold for Javascript, of course, because the language is untyped and we have to construct our own runtime.

#### From pure functions to actions

So far we lifted n-ary pure functions into the context of `n` applicative values. If we want to determine the next effect by the previous dynamic value, lifting a pure function is not enough. We need a way to intermingle the value and context level. In order to achieve it the function itself must return a value wrapped in the same effectful context as the corresponding monadic computation. Such a function is called an action. An action is not impure, but it may represent an effectful computation, provided it is used as part of an applicative or monadic computation:

```javascript
// Functor

const arrMap = f => xs =>
  xs.map((x, i) => f(x, i));

// Applicative

const arrAp = tf => xs =>
  arrFold(acc => f =>
    arrAppend(acc)
      (arrMap(x => f(x)) (xs)))
        ([])
          (tf);

// auxiliary functions

const arrFold = f => init => xs => {
  let acc = init;
  
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (xs[i], i);

  return acc;
};

const arrAppend = xs => ys =>
  (xs.push.apply(xs, ys), xs);

const comp = f => g => x => f(g(x));

// action

const foo = x => y =>
  y === null
    ? []
    : [x, y];

// MAIN

// result of the action interpreted as a value
arrAppend(
  foo(1) (2)) 
    (foo(3) (null)); // [1, 2, 3]

// result of the action interpreted as a computation
arrAp(
  arrMap(foo)
    ([1, 2]))
      ([3, null]); // [[1, 3], [], [2, 3], []]
```
[run code](https://repl.it/@scriptum/TubbyUnconsciousVolume)

If we use `foo` in a non-functorial context its result is treated like an ordinary value, which is a collection of values of natural numbers in the example above. However, if we use it as part of an applicative computation, the result is interpreted differently. It now represents a computation, namely a non-deterministic one. Since `foo` is an action that returns a value wrapped in an effectful context, the next effect can depend on the previous value. But now we are stuck with a nested context. The desired result is `[1, 3, 2, 3]`. Obviously actions are only half the solution.

#### The `join` operation

How about joining two effectful contexts, provided they are of the same type:

```javascript
// Monad

const arrJoin = xs =>
  arrFold(arrAppend) ([]) (xs);

// MAIN

arrJoin(
  arrMap(x =>
    arrJoin(
      arrMap(y =>
        y === null
          ? []
          : [x, y])
              ([3, null])))
                ([1, 2])); // [1, 3, 2, 3]
 ```
[run code](https://repl.it/@scriptum/FragrantSugaryObjectpool)

Have you seen how the computational structure has changed from a compositional to a nested form using closures? This is typical for a monadic computation. `join` is a sufficient operation and yields the expected result. Composing `map` with `join` is not particularly convenient though. Can we do better?

#### The `chain` operation

`chain` collapses the previous and the next context and thus combines `map` and `join` semantically:

```javascript
// Monad

const arrChain = mx => fm =>
  arrFold(acc => x =>
    arrAppend(acc) (fm(x))) ([]) (mx);

// MAIN

arrChain([1, 2]) (x =>
  arrChain([3, null]) (y =>
    y === null
      ? []
      : [x, y])); // [1, 3, 2, 3]
```
[run code](https://repl.it/@scriptum/HarmoniousAdorableScript)

In other functional languages this combinator is known as `flatmap`. You can transform `chain` to `join` and vice versa with the following laws:

```
= denotes equivalence
fm denotes an action
mx denotes a pure value x in an effectful context m
id denotes the identity function

join(mx) = chain(mx) (id)
chain(mx) (fm) = join(map(fm) (mx))
```
### Value/effect dependency

The characteristic property of monads is their ability to choose the next effect depending on a previous value. This feature presupposes that the next effect must depend on the previous one, because you cannot have one dependency without the other. Let us illustrate these dependencies in a more schematic manner. Given is an effectful computation `F<A>` where `A` is the result value of a previous effectful computation. It applies:

```
F   is an effectul context
A   is a pure value
~   denotes an x-may-depend-on-y relation
-   denotes an x-depends-on-y relation
</> denotes the direction of a dependency

Applicative constitutes:
F <~ F

Monad constitutes:
F <- F
A <~ F
```
Compared to applicatives this is a limitation of the monadic concept. We can demonstrate it using asynchronous computations that are run in parallel or in sequence:

```javascript
// record constructor

const record = (type, o) =>
  (o[type.name || type] = type.name || type, o);

// PARALLEL

const Parallel = par => record(
  Parallel,
  thisify(o => {
    o.par = (res, rej) =>
      par(x => {
        o.par = k => k(x);
        return res(x);
      }, rej);
    
    return o;
  }));

// Functor

const parMap = f => tx =>
  Parallel((res, rej) =>
    tx.par(x => res(f(x)), rej));

// Applicative

const parAp = tf => tx =>
  Parallel((res, rej) =>
    parAnd(tf) (tx)
      .par(([f, x]) =>
         res(f(x)), rej));

const parOf = x => Parallel((res, rej) => res(x));

// TASK

const Task = task => record(
  Task,
  thisify(o => {
    o.task = (res, rej) =>
      task(x => {
        o.task = k => k(x);
        return res(x);
      }, rej);
    
    return o;
  }));

// Functor

const taskMap = f => mx =>
  Task((res, rej) =>
    mx.task(x => res(f(x)), rej));

// Applicative

const taskAp = tf => mx =>
  Task((res, rej) =>
     tf.task(f =>
       mx.task(x =>
         res(f(x)), rej), rej));

const taskOf = x => Task((res, rej) => res(x));

// Monad

const taskChain = mx => fm =>
  Task((res, rej) =>
    mx.task(x =>
      fm(x).task(res, rej), rej));

// auxiliary functions

const id = x => x;
const thisify = f => f({});
const comp = f => g => x => f(g(x));
const add = x => y => x + y;

const delayParallel = f => ms => x =>
  Parallel((res, rej) => setTimeout(comp(res) (f), ms, x));

const delayTask = f => ms => x =>
  Task((res, rej) => setTimeout(comp(res) (f), ms, x));

// MAIN

const mainParallel = parAp(parMap(add)
  (delayParallel(id) (1000) (2)))
    (delayParallel(id) (1000) (3));

const mainTask = taskChain(
  delayTask(id) (1000) (2)) (x =>
    taskChain(delayTask(id) (1000) (3))
      (y => taskOf(x + y)));

// parallel addition: 2 * 1000ms = 1000ms
mainParallel.par(console.log); // logs 5 after 1000ms

// sequential addition: 2 * 1000ms = 2000ms
mainTask.task(console.log); // logs 5 after 2000ms
```
[run code](https://repl.it/@scriptum/LimeBraveFlatassembler)

`Task` performs its effect in sequence whereas `Parallel` runs it in parallel. `Task` implements `Monad` and thus also `Applicative`. `Parallel` on the other hand only implements `Applicative`, because a monad cannot perform its effects in parallel by design. You might wonder why I declared `Parallel` in the first place, instead of implementing `Task`'s `Applicative` instance with in parallel semantics. Having a monadic type whose `Applicative` behaves differently is considered bad practice. This is only a convention but a useful one that you should adhere to.

Although monadic effects are usually performed in sequence, there are instances that exhibit a non-deterministic effect order. I still believe the idea of monads as effect sequencing operators is still helpful, even though It might be a simplification for some edge cases.

The attentive reader may have already noticed that a monad is not necessary for the above task, because the next effect does not depend on a previous value. Usually you should favor applicatives over monads for such computations, however, for the sake of comparability I used the monad machinery.

### Term structure

The expressiveness of monads arises from their special computational structure. They form nested closures so that an inner action has access to the free variables of outer actions. We know this structure from curried functions:

```javascript
           x =>            y =>            z => /* function body */  // curried function
chain(mx) (x => chain(my) (y => chain(mz) (z => /* action body */))) // monadic action
```
A monadic computation basically shares the structure of a curried function, except that for every action layer the pure value is first pulled out of its effectful context and is then provided as an argument to the subsequent inner action. The unwrapping is carried out by machinery supplied by the monad instance. Unlike with curried functions we have to provide arguments to nested actions in place right away.

As opposed to applicative a monadic computation does not lift a pure function but embodies the effectful action itself. It conflates lifting and effect execution or in other words value and context layer to enable the previous-value/next-effect dependency. There is no monadic chaining without nesting. You cannot abstract from this structure, unless you resort to macros or other preprocessors. Every action layer has the same shape: It takes a pure value and returns a potentially transformed value within an effectful context. This form of self-similarity is a common concept in math.

### Essentially monadic

Since we should always prefer the simpler abstraction over the more complex one we should only use monad whenever possible and applicative otherwise. But what computation is essentially monadic? In other words what does it mean in practice that the next effect must depend on a previous value? Let us take apart two `Monad` instances to sharpen our instincts.

#### Array instance

An essentially monadic computation of the array instance affects the shape of the result array:

```javascript
// action

const foo = x => y =>
  y === null
    ? []
    : [x, y];

// MAIN

// Apllicative

arrAp(
  arrMap(foo)
    ([1, 2]))
      ([3, 4]); // [[1, 3], [1, 4], [2, 3], [2, 4]]

arrAp(
  arrMap(foo)
    ([1, 2]))
      ([3, null]); // [[1, 3], [], [1, 4], []]

// Monadic

arrChain([1, 2]) (x =>
  arrChain([3, 4]) (y =>
    foo(x) (y))); // [1, 3, 1, 4, 2, 3, 2, 4]

arrChain([1, 2]) (x =>
  arrChain([3, null]) (y =>
    foo(x) (y))); // [1, 3, 1, 4]
```
[run code](https://repl.it/@scriptum/QueasyFrenchAnalysts)

With applicatives it does not matter what we do the length of the resulting arrays is determined at compile time and thus known upfront. The monadic computation on the other hand can yield arrays of different length depending on a previous dynamic value, which is only evaluated at runtime. Please note that in the example above I only used static array literals for the sake of simplicity.

#### Function instance

An essentially monadic computation of the function instance affects the number of function applications. We can apply the next function not at all, once or several times depending on a previous value. Applying a function not at all is kind of like short circuiting the computation:

```javascript
// FUNCTION

// Applicative

const funAp = tf => tg => x =>
  tf(x) (tg(x));

// Monad

const funChain = mg => fm => x =>
  fm(mg(x)) (x);

// auxiliary functions

const log = x => console.log(x);

const myDiv = env => x => y => {
  const r = x / y;
  if (env.debug) log(r);
  return r;
};

const mySqr = env => x => {
  const r = x * x;
  if (env.debug) log(r);
  return r;
};

// MAIN

const mainA = funAp(
  funAp(env =>
    env.y === 0
      ? _ => _ => _ => Infinity
//      ^^^^^^^^^ redundant function application
      : f => g => x => f(g(x)) (env.y))
//                     ^^^^^^^ no explicit env passing
        (myDiv))
          (mySqr);

const mainM = funChain(myDiv) (f => env =>
  env.y === 0
    ? _ => Infinity
    : funChain(mySqr) (g => env =>
        x => f(g(x)) (env.y)) (env));
//           ^^^^^^^ no explicit env passing

mainA({debug: true, y: 4}) (6); // logs 36, 9 and yields 9
mainA({debug: true, y: 0}) (6); // logs nothing and yields Infinity

mainM({debug: true, y: 4}) (6); // logs 36, 9 and yields 9
mainM({debug: true, y: 0}) (6); // logs nothing and yields Infinity
```
[run code](https://repl.it/@scriptum/UnpleasantViolentProlog)

The difference between the applicative and monadic computation is subtle. With applicative we have to go through the entire computational structure, because each function has to be called exactly once. All we can do is ignore the respective arguments. With monads we can simply short circuit the computation by not performing the next effect at all.

### Types of constructor results

There are two distinct types of constructor results in functional programming. A result like `[1, 2, 3]`, which happens to be in literal form in this example, can be used for the purpose of

* obtaining a collection of values of type natural number
* obtaining a non-deterministic computation that may yield none, one or several results

This means we can interpret `[1, 2, 3]` either as an ordinary value or as a computation with a specific effect, namely non-determinism in the given example. Depending on what purpose we pick we get completely different results:

```javascript
// MAIN

// value purpose
arrChain([1, 2, 3]) (x =>
  arrChain([4, 5, 6]) (y =>
    arrOf([]))); // [[], [], [], [], [], [], [], [], []]

// computation purpose
arrChain([1, 2, 3]) (x =>
  arrChain([4, 5, 6]) (y =>
    [])); // []
```
[run code](https://repl.it/@scriptum/BriskRotatingField)

The given example may be contrived but it illustrates the subtle difference between the two different types of constructor results quite effectively. Monads or the underlying functors respectively turn ordinary values into a computation with specific computational effects, provided these values are used at the right lexical position. You can think of a monad as a semantics machine or a small embedded effect-specific language.

### Monads at the type level

Here are the hypothetical monad types provided Typescript would support higher-kinded types:

```
// hypothetical type
type chain <M, A, B>(ft: (x: A) => M<B>) => (tx: M<A>) => M<B>;
```
Just like `map` and `ap` `chain` is a function application operator. Please note that I use `chain` with flipped arguments for the sake of symmetry:

```
<   A, B>( f:   (x: A) => B   ) => ( x:   A ) =>   B ; // function application
<F, A, B>( f:   (x: A) => B   ) => (tx: F<A>) => F<B>; // functor lifting
<F, A, B>(tf: F<(x: A) => B  >) => (tx: F<A>) => F<B>; // applicative lifting
<M, A, B>(ft:   (x: A) => M<B>) => (tx: M<A>) => M<B>; // monadic binding
```
### No escape from the monad

Once a computation yields a monad you cannot escape its algebraic structure anymnore. The result value is trapped in the monad. This corresponds to the functor and applicative functor behavior. If you want to apply a function to a monadic value, you need to promote the function not to unwrap the value. You can write an operation function that unwraps the monad, of course, but such a function is beyond the monadic API and hence only works for the specific monad it is implemented for. So why is an unwrapping operation not part of the API? Because it does not exists for all monads. It would render the concept less general.

### Abstracting from nested application

We cannot abstract from the nested computational structure in general without compromising the effect layer or losing the ability of monads to determine the next effect on the previous value. However, we can abstract from the `chain` operator by applying monads like applicatives:

```javascript
// Monad

const chain3 = chain => tx => ty => tz => fm =>
  chain(chain(chain(tx) (x => fm(x)))
    (gm => chain(ty) (y => gm(y))))
      (hm => chain(tz) (z => hm(z)));

// MAIN

const main = chain3(arrChain)
  ([1,2])
    ([3,4])
      ([5,6])
        (x => [y => [z => [x, y, z]]]);

const main2 = chain3(arrChain)
  ([1,2])
    ([3,4])
      ([5,6])
        (x => x === 1 ? [] : [y => [z => [x, y, z]]]);

main; // [1, 3, 5, 1, 3, 6, 1, 4, 5, 1, 4, 6, 2, 3, 5, 2, 3, 6, 2, 4, 5, 2, 4, 6]
main2; // [2, 3, 5, 2, 3, 6, 2, 4, 5, 2, 4, 6]
```
[run code](https://repl.it/@scriptum/ClearcutWateryPerl)

The `chain3` abstraction is a little less efficient than the original monadic computations, because for every additional monadic value we have to perform the underlying effect once additional to unwrap the next action, namely `gm` and `hm`. Please note that just like with the `liftA` combinator family `chain#` establishes an arity aware family of combinators.

### Action composition Ã  la Kleisli

The composition of monadic actions is called Kleisli composition. Just like with ordinary function composition the operators are arity aware and each arity includes a right-to-left and left-to-right form:

```javascript
const compk = chain => fm => gm =>
  x => chain(gm(x)) (fm);

const compk3 = chain => fm => gm => hm =>
  x => chain(chain(hm(x)) (gm)) (fm);

const pipek = chain => gm => fm =>
  x => chain(gm(x)) (fm);

const pipek3 = chain => hm => gm => fm =>
  x => chain(chain(hm(x)) (gm)) (fm);
```
Action composition is as static as function composition, but it takes place within an effectful context, namely non-determinism in the following example:

```javascript
// MAIN

const mainComp = compk3(arrChain)
  (x => x < 0 ? [""] : ["hi".repeat(x)])
    (x => [x, -x])
      (x => [x + 1, x + 2, x + 3]);

const mainPipe = pipek3(arrChain)
  (x => [x + 1, x + 2, x + 3])
    (x => [])
      (x => x < 0 ? [""] : ["hi".repeat(x)]);

mainComp(0); // ["hi", "", "hihi", "", "hihihi"]
mainPipe(0); // []
```
[run code](https://repl.it/@scriptum/CircularShoddyMonotone)

### Monadic laws

Every monad instance have to comply with the following laws:

```
=        denotes equivalence
fm/gm/hm denotes an monadic action
x        denotes a pure value
mx       denotes a pure value x in an monadic context m
pipek    denotes the reverse kleisli composition operator

chain(of(x)) (fm) = fm(x) // left identity
chain(mx) (of) = mx // right identity
chain(chain(mx) (fm)) (gm) = chain(mx) (x => chain(fm(x)) (gm)) // associativity

or alternatively expressed with kleisli composition:

pipek(of) (fm) = fm // left identity
pipek(fm) (of) = fm // right identity
pipek(pipek(fm) (gm)) (hm) = pipek(fm) (pipek(gm) (hm)) // associativity
```
### Recursion within a monad

Monads use actions, which are functions that return an effectful result. As with any other function we can define an action recursively in terms of itself. In doing so we are especially interested in defining the recursive step within `chain`, that is to say within the monad:

```javascript
// union constructor

const union = type => (tag, o) =>
  (o[type] = type, o.tag = tag.name || tag, o);

const match = (tx, o) =>
  o[tx.tag] (tx);

// OPTION

const Option = union("Option");

const None = Option("None", {});

const Some = some => Option(Some, {some});

// Monad

const optChain = mx => fm =>
  match(mx, {
    None: _ => None,
    Some: ({some: x}) => fm(x)
  });

const optOf = x => Some(x);

// MAIN

const sum = xs => {
  const go = (tx, i) =>
    i === xs.length
      ? tx
      : optChain(tx) (acc =>
          optChain(xs[i]) (x => go(optOf(acc + x), i + 1)))

  return go(optOf(0), 0);
};

const xs = [Some(1), Some(2), Some(3), Some(4), Some(5)],
  ys = [Some(1), None, Some(3), Some(4), Some(5)],
  zs = Array(1e5).fill(Some(1));

sum(xs); // Some(15)
sum(ys); // None
sum(zs); // stack overflow
```
[run code](https://repl.it/@scriptum/AgreeableIrritatingFact)

Monads inherited the property every function includes: Once defined recursively they are not stack-safe. Optimizing the call stack of monadic recursion away is tricky business. However, monads were not monads if it was not for a monad which offers such safety. Unfortunately we need a monad transformer to combine a stack-safe monad with another one. I will return to this issue in the chapter on monad transformer stacks.

### Monads from an imperative perspective

If you have an imperative background I find the programmable semicolon metaphor quite helpful. In imperative programming we use statements, which are completely decoupled from each other. In order to use the result from a previous statement we have to rely on intermediate values. Every statement may include various side effects. This it hard to tell, because they are implicit. Monads allow to compose such effectful statements in a principled fashion. Since statements are often concluded with a semicolon, you can think of a monad as a programmable and composable semicolon.

### Monads are orthogonal to I/O

TODO

### Monads do not compose

TODO

### Editor's note

If you enjoyed this chapter please ðŸŒŸ scriptum here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/course/ch-016.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc) | [next chapter &gt;](https://github.com/kongware/scriptum/blob/master/course/ch-019.md)
